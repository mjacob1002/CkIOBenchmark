
Running as 256 OS processes: ./iotest TEST_FILES/31.txt 256
charmrun> /usr/bin/setarch x86_64 -R mpirun -np 256 ./iotest TEST_FILES/31.txt 256
Charm++> Running on MPI library: Open MPI v4.0.5, package: Open MPI spack@br012.ib.bridges2.psc.edu Distribution, ident: 4.0.5, repo rev: v4.0.5, Aug 26, 2020 (MPI standard: 3.1)
Charm++> Level of thread support used: MPI_THREAD_SINGLE (desired: MPI_THREAD_SINGLE)
Charm++> Running in non-SMP mode: 256 processes (PEs)
Converse/Charm++ Commit ID: v7.1.0-devel-237-ga3f055e15
Isomalloc> Synchronized global address space.
CharmLB> Load balancer assumes all CPUs are same.
Charm++> Running on 2 hosts (2 sockets x 64 cores x 1 PUs = 128-way SMP)
Charm++> cpu topology info is gathered in 0.045 seconds.
CharmLB> Load balancing instrumentation for communication is off.
Total time: 0.803984
[Partition 0][Node 0] End of program
[1675925008.279391] [r294:8347 :0]      tag_match.c:61   UCX  WARN  unexpected tag-receive descriptor 0x1555417cdec0 was not matched
[1675925008.279412] [r294:8347 :0]      tag_match.c:61   UCX  WARN  unexpected tag-receive descriptor 0x1555417ddf40 was not matched
[1675925008.279426] [r294:8347 :0]      tag_match.c:61   UCX  WARN  unexpected tag-receive descriptor 0x1555417edfc0 was not matched
[1675925008.279433] [r294:8347 :0]      tag_match.c:61   UCX  WARN  unexpected tag-receive descriptor 0x1555417addc0 was not matched
